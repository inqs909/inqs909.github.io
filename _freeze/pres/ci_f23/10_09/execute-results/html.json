{
  "hash": "7962fccdc41e6847a6b6a9e7bd92a853",
  "result": {
    "engine": "knitr",
    "markdown": "---\ntitle: \"Bayesian Mixed Effects Models and Cats\"\nsubtitle: \"inqs.info/pres/ci_f23/10_09\"\nauthor: \"Isaac Quintanilla Salinas\"\nformat: \n  revealjs:\n    touch: false\n    controls: true\n    pointer:\n      pointerSize: 32\n    incremental: false\n    slide-number: true\n    css: styles.css\nknitr:\n  opts_chunk: \n    echo: true\n    eval: true\n    message: false\n    warnings: false\n    comment: \"#>\" \nrevealjs-plugins:\n  - pointer\n---\n\n\n\n\n\n# \n\n::: columns\n::: {.column width=\"50%\"}\n::: {style=\"font-size: 60px; padding: 120px 0;\"}\n**Motivation**\n:::\n:::\n\n::: {.column width=\"50%\"}\n![](https://media.tenor.com/L8bcFLYjPhUAAAAd/parkour-cat.gif)\n:::\n:::\n\n## San Bernardino Desert (Only Real Part)\n\n![](https://upload.wikimedia.org/wikipedia/commons/0/05/Sand_to_Snow_National_Monument.jpg){fig-align=\"center\"}\n\n## Study *Felis*\n\n::: columns\n::: {.column width=\"30%\"}\n### *F. catus*\n\n![](https://inaturalist-open-data.s3.amazonaws.com/photos/129658776/large.jpg){fig-align=\"left\"}\n:::\n\n::: {.column width=\"30%\"}\n### *F. silvestris*\n\n![](https://upload.wikimedia.org/wikipedia/commons/d/d0/Felis_silvestris_silvestris_Luc_Viatour.jpg){fig-align=\"center\" width=\"455\"}\n:::\n\n::: {.column width=\"30%\"}\n### *F. margarita*\n\n![](https://upload.wikimedia.org/wikipedia/commons/thumb/a/af/Felis_margarita_10.jpg/220px-Felis_margarita_10.jpg){fig-align=\"right\"}\n:::\n:::\n\n## Study\n\n**We are interested in seeing if wearing a flea collar will affect a cat's weight over time.**\n\n## Outcome (Y): Weight of a cat\n\n![](https://www.kentscientific.com/Customer-Content/www/products/Photos/Original/SCL-4000.jpg){fig-align=\"center\"}\n\n## Predictors (X)\n\n-   Experimental Variable\n    -   Flea Collar\n-   Alertness\n-   Hair Coat\n-   Time\n\n## Model\n\n$$\nY = \\boldsymbol X^\\mathrm T\\boldsymbol \\beta + \\varepsilon\n$$\n\n-   $Y$: Outcome of Interest\n\n-   $\\boldsymbol X = (1, t, X_1, X_2, X_3)^\\mathrm T$: Predictor Variables\n\n-   $\\boldsymbol \\beta=(\\beta_0, \\beta_1, \\beta_2, \\beta_3, \\beta_4)^\\mathrm T$: Regression Coefficients\n\n-   $\\varepsilon \\sim N(0, \\sigma^2)$\n\n::: fragment\n**Fit with Linear Regression**\n:::\n\n## Linear Regression Assumptions\n\n::: incremental\n-   Residuals follow a normal distribution\n\n-   There is a linear trend\n\n-   Constant Variance\n\n-   Observations are Independent\n:::\n\n## Our Study\n\n::: incremental\n-   Residuals follow a normal distribution ✅\n\n-   There is a linear trend ✅\n\n-   Constant Variance ✅\n\n-   Observations are Independent ❌\n:::\n\n## Why is this a problem?\n\n::: columns\n::: {.column width=\"50%\"}\n::: {.fragment .incremental}\n-   Cannot Construct Likelihood Function\n\n-   Biased Standard Errors\n\n-   Uncontrollable Variation\n:::\n:::\n\n::: {.column width=\"50%\"}\n\n\n::: {.cell}\n::: {.cell-output-display}\n![](10_09_files/figure-revealjs/unnamed-chunk-2-1.png){width=960}\n:::\n:::\n\n\n:::\n:::\n\n## Species\n\n![](https://www.researchgate.net/publication/340201788/figure/fig1/AS:873450486902784@1585258232035/Maximum-Likelihood-phylogenetic-tree-constructed-using-whole-genome-SNPs-data-of-wildcat.jpg){fig-align=\"center\"}\n\n## Maine Coon\n\n![](https://www.thesprucepets.com/thmb/MzKr6fC-v8W4D4oz2p9wWCwAFms=/2119x0/filters:no_upscale():strip_icc()/GettyImages-1189893683-e0ff70596b3b4f0687ba573e5a671f74.jpg){fig-align=\"center\"}\n\n## Environments\n\n::: columns\n::: {.column width=\"30%\"}\n::: {.fragment fragment-index=\"1\"}\n### Indoor\n\n![](https://www.zooplus.ie/magazine/wp-content/uploads/2021/07/Indoor-Cat.jpeg){fig-align=\"left\"}\n:::\n:::\n\n::: {.column width=\"30%\"}\n::: {.fragment fragment-index=\"3\"}\n### In-Between\n\n![](https://images.thdstatic.com/productImages/59613c83-0288-40bc-bf54-a15afca9d18f/svn/petsafe-cat-doors-hpa11-10876-31_600.jpg){fig-align=\"center\"}\n:::\n:::\n\n::: {.column width=\"30%\"}\n::: {.fragment fragment-index=\"2\"}\n### Outside\n\n![](https://www.humanesociety.org/sites/default/files/2018/10/feral-cat-353896.jpg){fig-align=\"right\"}\n:::\n:::\n:::\n\n## Longitudinal Measurements\n\n\n\n::: {.cell}\n::: {.cell-output-display}\n![](10_09_files/figure-revealjs/unnamed-chunk-3-1.png){width=960}\n:::\n:::\n\n\n\n# \n\n::: columns\n::: {.column width=\"50%\"}\n::: {style=\"font-size: 60px; padding: 120px 0;\"}\n**Models**\n:::\n:::\n\n::: {.column width=\"50%\"}\n![](https://media.tenor.com/ITQdqRCN-WQAAAAd/cat-cat-walk.gif)\n:::\n:::\n\n## Original Model\n\n$$\nY_{k} = \\boldsymbol X_{k}^\\mathrm T\\boldsymbol \\beta + \\varepsilon_{k}\n$$\n\n-   $k = 1, \\ldots, N$\n\n-   $N$: Number of all observations\n\n-   $Y_{k}$: Outcome of Interest\n\n-   $\\boldsymbol X_{k} = (1, t_{k}, X_{k1}, X_{k2}, X_{k3})^\\mathrm T$: Predictor Variables\n\n-   $\\boldsymbol \\beta=(\\beta_0, \\beta_1, \\beta_2, \\beta_3, \\beta_4)^\\mathrm T$: Regression Coefficients\n\n-   $\\varepsilon_{k}\\sim N(0, \\sigma^2)$: Error Term\n\n## Multilevel Model Approach\n\n::: incremental\n-   Different cats share characteristics that may introduce correlation\n-   To account for the correlation, we will group cats based on the characteristics\n-   Each group will get a set of random effects to induce the correlation\n:::\n\n## Framework\n\n\n\n::: {.cell}\n::: {.cell-output-display}\n![](10_09_files/figure-revealjs/unnamed-chunk-4-1.png){width=960}\n:::\n:::\n\n\n\n## Multilevel Model\n\n$$\nY = \\boldsymbol X^\\mathrm T\\boldsymbol \\beta + b_i + b_j + b_k +\\varepsilon\n$$\n\n-   Random Effects (RE) induce the correlation in the model\n\n-   Different RE can be used based on the grouping mechanism\n\n-   We assume RE groups are independent of each other\n\n## A Linear Model w/ Repeated Measurements\n\n$$\nY_{ij} = \\boldsymbol X_{ij}^\\mathrm T\\boldsymbol \\beta + \\varepsilon_{ij}\n$$\n\n-   $Y_{ij}=Y_i(t_{ij})$: Outcome of Interest\n\n-   $\\boldsymbol X_{ij} = (1, t_{ij}, X_{ij1}, X_{ij2}, X_{ij3})^\\mathrm T$: Predictor Variables\n\n-   $\\boldsymbol \\beta=(\\beta_0, \\beta_1, \\beta_2, \\beta_3, \\beta_4)^\\mathrm T$: Regression Coefficients\n\n-   $\\varepsilon_{ij}\\sim N(0, \\sigma^2)$: Error Term\n\n## Animal-Specific Random Effects\n\n$$\n\\boldsymbol b_i = (b_{i0}, b_{i1})^\\mathrm T \\sim N_2(\\boldsymbol 0, \\boldsymbol \\Sigma_b)\n$$\n\n::: columns\n::: {.column width=\"50%\"}\n### Mean Vector\n\n$$\n\\boldsymbol 0 = \\left(\\begin{array}{c}\n0 \\\\\n0\n\\end{array}\n\\right)\n$$\n:::\n\n::: {.column width=\"50%\"}\n### Covariance Matrix\n\n$$\n\\boldsymbol \\Sigma_b = \\left(\\begin{array}{cc}\n\\sigma_{b0}^2 & \\sigma_{b01} \\\\\n\\sigma_{b01} & \\sigma_{b1}^2 \n\\end{array}\n\\right)\n$$\n:::\n:::\n\n## Add Animal-Specific Random Effects\n\n$$\nY_{ij} = \\boldsymbol X_{ij}^\\mathrm T\\boldsymbol \\beta + b_{i0} + t_{ij} b_{i1} + \\varepsilon_{ij}\n$$\n\n::: columns\n::: {.column width=\"50%\"}\n-   $Y_{ij}=Y_i(t_{ij})$: Outcome of Interest\n\n-   $\\boldsymbol X_{ij} = (1, t_{ij}, X_{ij1}, X_{ij2}, X_{ij3})^\\mathrm T$: Predictor Variables\n\n-   $\\boldsymbol \\beta=(\\beta_0, \\beta_1, \\beta_2, \\beta_3, \\beta_4)^\\mathrm T$: Regression Coefficients\n\n-   $\\varepsilon_{ij}\\sim N(0, \\sigma^2)$: Error Term\n:::\n\n::: {.column width=\"50%\"}\n-   $\\boldsymbol b_i = (b_{i0}, b_{i1})^\\mathrm T \\sim N_2(\\boldsymbol 0, \\boldsymbol \\Sigma_b)$\n:::\n:::\n\n## Environmental-Specific Random Effects\n\n$$\n\\boldsymbol b_{env} = (b_{in}, b_{bw}, b_{out})^\\mathrm T \\sim N_3(\\boldsymbol 0, \\sigma^2_b\\boldsymbol I_3)\n$$\n\n::: columns\n::: {.column width=\"50%\"}\n### Mean Vector\n\n$$\n\\boldsymbol 0 = \\left(\\begin{array}{c}\n0 \\\\\n0 \\\\\n0\n\\end{array}\n\\right)\n$$\n:::\n\n::: {.column width=\"50%\"}\n### Covariance Matrix\n\n$$\n\\boldsymbol \\Sigma_b = \\left(\\begin{array}{cc}\n1 & 0 & 0 \\\\\n0 & 1 & 0 \\\\\n0 & 0 & 1  \n\\end{array}\n\\right)\n$$\n:::\n:::\n\n## Add Environmental-Specific Random Effects\n\n$$\nY_{ij} = \\boldsymbol X_{ij}^\\mathrm T\\boldsymbol \\beta + b_{i0} + t_{ij} b_{i1} + b_{env(i)} +  \\varepsilon_{ij}\n$$\n\n::: columns\n::: {.column width=\"50%\"}\n-   $Y_{ij}=Y_i(t_{ij})$\n\n-   $\\boldsymbol X_{ij} = (1, t_{ij}, X_{ij1}, X_{ij2}, X_{ij3})^\\mathrm T$\n\n-   $\\boldsymbol \\beta=(\\beta_0, \\beta_1, \\beta_2, \\beta_3, \\beta_4)^\\mathrm T$\n\n-   $\\varepsilon_{ij}\\sim N(0, \\sigma^2)$\n:::\n\n::: {.column width=\"50%\"}\n-   $\\boldsymbol b_i = (b_{i0}, b_{i1})^\\mathrm T \\sim N_2(\\boldsymbol 0, \\boldsymbol \\Sigma_b)$\n-   $b_{env(i)} \\in \\boldsymbol b_{env}=(b_{in}, b_{bw}, b_{out})^\\mathrm T$\n-   $\\boldsymbol b_{env} \\sim N_3(\\boldsymbol 0, \\sigma^2_{env} \\boldsymbol I_3)$\n:::\n:::\n\n## Species Random Effects\n\n$$\n\\boldsymbol b_evo = (b_{cat}, b_{sil}, b_{mar})^\\mathrm T \\sim N_3(\\boldsymbol 0, \\boldsymbol \\Sigma_{evo})\n$$\n\n::: columns\n::: {.column width=\"50%\"}\n### Mean Vector\n\n$$\n\\boldsymbol 0 = \\left(\\begin{array}{c}\n0 \\\\\n0 \\\\\n0\n\\end{array}\n\\right)\n$$\n:::\n\n::: {.column width=\"50%\"}\n### Covariance Matrix\n\n$$\n\\boldsymbol \\Sigma_b = \\left(\\begin{array}{cc}\n\\sigma_{c}^2 & \\sigma_{cs} & \\sigma_{cm}\\\\\n\\sigma_{sc} & \\sigma_{s}^2 & \\sigma_{sm} \\\\\n\\sigma_{mc} & \\sigma_{ms} & \\sigma_{m}^2 \\\\\n\\end{array}\n\\right)\n$$\n:::\n:::\n\n## Add Species Random Effects\n\n$$\nY_{ij} = \\boldsymbol X_{ij}^\\mathrm T\\boldsymbol \\beta + b_{i0} + t_{ij} b_{i1} + b_{env(i)} + b_{evo(i)} + \\varepsilon_{ij}\n$$\n\n::: columns\n::: {.column width=\"50%\"}\n-   $Y_{ij}=Y_i(t_{ij})$\n\n-   $\\boldsymbol X_{ij} = (1, t_{ij}, X_{ij1}, X_{ij2}, X_{ij3})^\\mathrm T$\n\n-   $\\boldsymbol \\beta=(\\beta_0, \\beta_1, \\beta_2, \\beta_3, \\beta_4)^\\mathrm T$\n\n-   $\\varepsilon_{ij}\\sim N(0, \\sigma^2)$\n:::\n\n::: {.column width=\"50%\"}\n-   $\\boldsymbol b_i = (b_{i0}, b_{i1})^\\mathrm T \\sim N_2(\\boldsymbol 0, \\boldsymbol \\Sigma_b)$\n-   $b_{env(i)} \\in \\boldsymbol b_{env}=(b_{in}, b_{bw}, b_{out})^\\mathrm T$\n-   $\\boldsymbol b_{env} \\sim N_3(\\boldsymbol 0, \\sigma^2_{env} \\boldsymbol I_3)$\n-   $b_{evo(i)} \\in \\boldsymbol b_{env}=(b_{cat}, b_{sil}, b_{mar})^\\mathrm T$\n-   $\\boldsymbol b_{evo} \\sim N_3(\\boldsymbol 0, \\boldsymbol \\Sigma_{evo})$\n:::\n:::\n\n## Final Model?\n\n## Me ...\n\n![](https://www.rd.com/wp-content/uploads/2022/04/GettyImages-1310147575.jpg?fit=700%2C466){fig-align=\"center\"}\n\n## Me ...\n\n::: columns\n::: {.column width=\"50%\"}\n::: incremental\n-   We Must Use Random Effects\n\n-   We Must Use a Bayesian Approach\n:::\n:::\n\n::: {.column width=\"50%\"}\n![](https://www.rd.com/wp-content/uploads/2022/04/GettyImages-1310147575.jpg?fit=700%2C466){fig-align=\"center\"}\n:::\n:::\n\n## Add Correlation Matrix {.smaller}\n\n$$\n\\widehat{\\mathrm{cov}}( \\boldsymbol Y_i) = \\boldsymbol \\Sigma_i = \\sigma^2 \\boldsymbol \\Lambda_i\n$$\n\n::: fragment\n$$\n\\boldsymbol \\Lambda_i  = \\left(\\begin{array}{cccc}\n1 & \\rho^{(t_{i1}-t_{i2})^2} & \\rho^{(t_{i1}-t_{i3})^2} & \\rho^{(t_{i1}-t_{i4})^2}\\\\\n\\rho^{(t_{i2}-t_{i1})^2} & 1 & \\rho^{(t_{i2}-t_{i3})^2} & \\rho^{(t_{i2}-t_{i4})^2}\\\\\n\\rho^{(t_{i3}-t_{i1})^2} & \\rho^{(t_{i3}-t_{i2})^2} & 1 & \\rho^{(t_{i3}-t_{i4})^2}\\\\\n\\rho^{(t_{i4}-t_{i1})^2} & \\rho^{(t_{i4}-t_{i2})^2} & \\rho^{(t_{i4}-t_{i3})^2} & 1\\\\\n\\end{array}\n\\right)\n$$\n:::\n\n::: fragment\n$$\n\\boldsymbol \\Lambda_i  = \\left(\\begin{array}{cccc}\n1 & \\rho^{|t_{i1}-t_{i2}|} & \\rho^{|t_{i1}-t_{i3}|} & \\rho^{|t_{i1}-t_{i4}|}\\\\\n\\rho^{|t_{i2}-t_{i1}|} & 1 & \\rho^{|t_{i2}-t_{i3}|} & \\rho^{|t_{i2}-t_{i4}|}\\\\\n\\rho^{|t_{i3}-t_{i1}|} & \\rho^{|t_{i3}-t_{i2}|} & 1 & \\rho^{|t_{i3}-t_{i4}|}\\\\\n\\rho^{|t_{i4}-t_{i1}|} & \\rho^{|t_{i4}-t_{i2}|} & \\rho^{|t_{i4}-t_{i3}|} & 1\\\\\n\\end{array}\n\\right)\n$$\n:::\n\n::: fragment\n$$\n\\rho \\in (-1, 1)\n$$\n:::\n\n## Final Model (for real, for now)\n\n$$\n\\boldsymbol Y_i \\sim N_4(\\boldsymbol \\mu_i, \\boldsymbol \\Sigma)\n$$\n\n$$\n\\mu_{ij} = \\boldsymbol X_{ij}^\\mathrm T\\boldsymbol \\beta + b_{i0} + b_{env(i)} + b_{evo(i)} + \\varepsilon_{ij}\n$$\n\n## Accounted Variation\n\n\n\n::: {.cell}\n::: {.cell-output-display}\n![](10_09_files/figure-revealjs/unnamed-chunk-5-1.png){width=960}\n:::\n:::\n\n\n\n# \n\n::: columns\n::: {.column width=\"50%\"}\n::: {style=\"font-size: 60px; padding: 120px 0;\"}\n**Bayesian Models**\n:::\n:::\n\n::: {.column width=\"50%\"}\n![](https://media.tenor.com/7lzxyYB36cIAAAAC/kittens-cute-kittens.gif)\n:::\n:::\n\n## Likelihood Function\n\n$$\nL(\\boldsymbol \\theta) \\propto \\prod_{i}f(\\boldsymbol y_i|b_i,b_{evo(i)},b_{env(i)};\\boldsymbol \\theta)f(b_i;\\boldsymbol \\theta)f(\\boldsymbol b_{evo};\\boldsymbol \\theta) f(\\boldsymbol b_{env};\\boldsymbol \\theta)\n$$\n\n$\\boldsymbol \\theta:$ all parameters involved in the model\n\n## Prior\n\n-   $\\sigma^2\\sim Gamma(\\alpha_1, \\beta_1)$\n\n-   $\\sigma^2_{env}\\sim Gamma(\\alpha_2, \\beta_2)$\n\n-   $\\boldsymbol \\beta \\sim N_p(\\boldsymbol 0, 10\\boldsymbol I)$\n\n-   $\\rho \\sim Unif(-1,1)$\n\n-   $\\Sigma_{evo}:$ Obtained from evolutionary biology databases OR Wishart Distribution\n\n-   $f(\\boldsymbol \\theta) = f(\\sigma^2)f(\\sigma_{env}^2)f(\\rho)f(\\boldsymbol \\beta)$\n\n## Likelihood X Prior\n\n$$\nL(\\boldsymbol \\theta) \\times f(\\boldsymbol \\theta)\n$$\n\n## Posterior Distribution\n\n$$\nf(\\boldsymbol  \\theta|\\boldsymbol Y) \\propto L(\\boldsymbol\\theta)f(\\boldsymbol \\theta)\n$$\n\n## Estimation\n\nEstimating the parameter require us to obtain the joint posterior distribution.\n\n::: fragment\nThis is challenging since we do not know the normalizing constant\n:::\n\n# \n\n::: columns\n::: {.column width=\"50%\"}\n::: {style=\"font-size: 60px; padding: 120px 0;\"}\n**Markov Chain Monte Carlo Methods**\n:::\n:::\n\n::: {.column width=\"50%\"}\n![](https://media.tenor.com/x5dpKrM1U6oAAAAd/vamonos-lets-go.gif)\n:::\n:::\n\n## Markov Chain {.smaller}\n\n::: incremental\n-   A Markov chain is a collection states of a certain phenomenom\n\n    -   $X^{(0)},X^{(1)},X^{(2)},X^{(3)},X^{(4)},X^{(5)},X^{(6)},X^{(7)}, \\cdots, X^{(k)}$\n\n-   The changing of the state is only dependent on the current state, not the previous states\n\n    -   $P\\left\\{X^{(k+1)}\\boldsymbol{\\Big|}X^{(k)},X^{(k-1)},X^{(k-2)},\\ldots,X^{(1)},X^{(0)}\\right\\}=P\\left\\{X^{(k+1)}\\boldsymbol{\\Big |}X^{(k)}\\right\\}$\n:::\n\n## Cat Markov Chains\n\n\n\n::: {.cell}\n::: {.cell-output-display}\n![](10_09_files/figure-revealjs/unnamed-chunk-6-1.png){width=960}\n:::\n:::\n\n\n\n## Markov Kernel\n\n::: columns\n::: {.column width=\"50%\"}\n::: incremental\n-   A Markov kernel provides the probability of going to another state, given the current state\n\n-   Also known a transition matrix\n:::\n:::\n\n::: {.column width=\"50%\"}\n::: fragement\n\n\n::: {.cell}\n::: {.cell-output-display}\n![](10_09_files/figure-revealjs/unnamed-chunk-7-1.png){width=960}\n:::\n:::\n\n\n:::\n:::\n:::\n\n## Stationary (limiting) distribution\n\n::: columns\n::: {.column width=\"50%\"}\n### Conditions\n\n::: incremental\n-   *Irreducibility:* The kernel allows for free movement of all the state space\n\n-   *Recurrent:* The chain will return to any nonnegligible set an infinite number of times\n\n-   *Aperiodic:* The chain can return to any state immediately\n:::\n:::\n\n::: {.column width=\"50%\"}\n### Resulting\n\n::: incremental\n-   $X^{(t)}\\rightarrow X$\n\n    -   Regardless of $X^{(0)}$\n\n-   $X \\sim f$\n\n    -   $f$: is a distribution function\n\n-   $\\frac{1}{T}\\sum_{t=1}^{T} h\\{X^{(t)}\\} \\rightarrow E_f\\{h(X)\\}$\n\n    -   $h$: any integrable function\n\n    -   by Law of Large Numbers\n:::\n:::\n:::\n\n## Markov Chains Monte Carlo\n\n::: incremental\n-   MCMC Methods are used to a distribution function that is not easily obtained.\n\n-   A Markov chain is contructed by simulating Monte Carlo Samples and accepted based on a certain criteria\n\n-   Based on the MCMC Central Limit Theorem, the Markov chain will construct a limiting distribution that is desired.\n:::\n\n## Metropolis-Hastings Algorithm\n\n-   The MH algorithm will generate target the distribution function $f$ a random variable\n\n-   The MH will generate a candidate from an easier distribution function $g$ for a Markov chain and accept it based on the Metropolis-Hastings Kernel\n\n-   With a large enough simulation, the resulting chain will have a limiting distribution of $f$\n\n## MH Algorithm\n\nGiven $x^{(t)}$ and targeting $f(x)$\n\n1.  Generate $y\\sim g(y|x^{(t)})$\n2.  $$\n    x^{(t+1)} =\\left\\{\\begin{array}{cc}\n    y &\\ \\mathrm{with\\ probability\\ } q(x^{(t)}, y)\\\\\n    x^{(t)} & \\mathrm{with\\ probability\\ } 1-q(x^{(t)}, y) \n    \\end{array}\\right. \n    $$\n\n$$\nq(x,y) = \\min\\left\\{\\frac{f(y)g(x|y)}{f(x)g(y|x)},1\\right\\}\n$$\n\n## Gibbs Sampler\n\n-   A Gibbs sampler is an extension of many univariate MCMC techniques to multivariate analysis\n\n-   The goal of the sampler is to generate a Markov chain that targets a joint distribution function\n\n-   The Gibbs Sampler achieves this by sampling from the conditional densities of the joint distribution function\n\n## Gibbs Sampler Algorithm for Trivariate RV\n\nGiven $x^{(t)}$, $y^{(t)}$, and $z^{(t)}$, we are targeting $f(x,y,z)$\n\n1.  Generate $x^{(t+1)}\\sim f(x|y^{(t)}, z^{(t)})$\n2.  Generate $y^{(t+1)}\\sim f(y|x^{(t+1)}, z^{(t)})$\n3.  Generate $z^{(t+1)}\\sim f(z|x^{(t+1)}, y^{(t+1)})$\n4.  Repeat previous until long enough chain is generated\n\n## Hamiltonian Monte Carlo\n\n-   Hamiltonian Monte Carlo is a relatively new MCMC technique used to construct the target distribution\n\n-   It utilizes Hamiltonian dynamics to simulate the next random variable\n\n-   The random variable is the accepted based the MH probability\n\n-   Using Hamiltonian dyanmics improves the mixing properties of the chain and draws are more targeted to the desired distribution\n\n# \n\n::: columns\n::: {.column width=\"50%\"}\n::: {style=\"font-size: 60px; padding: 120px 0;\"}\n**Simulation Study**\n:::\n:::\n\n::: {.column width=\"50%\"}\n![](https://media.tenor.com/NwY5ppxLs_oAAAAd/kitten-keybo.gif)\n:::\n:::\n\n## Simulation Parameters\n\n-   300 Cats\n\n-   5 Environments\n\n-   3 Species\n\n-   4 Repeated Measurements\n\n-   6000 Data Points\n\n## Model Parameters\n\n-   $b_i \\sim N( 0, 0.8)$\n\n-   $\\boldsymbol b_{env} \\sim N_5(\\boldsymbol 0, 1.5 \\boldsymbol I_5)$\n\n-   $\\boldsymbol b_{evo} \\sim N_3(\\boldsymbol 0, \\boldsymbol \\Sigma_{evo})$\n\n$$\n\\boldsymbol \\Sigma_{evo} = \\left(\n\\begin{array}{ccc}\n1 & 0.8 & 0.1\\\\\n0.8 & 1.3 & 0.43 \\\\\n0.1 & 0.43 & 1.9\n\\end{array}\n\\right)\n$$\n\n## Simulation Model\n\n$$\n\\boldsymbol Y_i \\sim N_4(\\boldsymbol \\mu_i, 1.5 \\boldsymbol \\Lambda_i) \n$$\n\n$$\n\\boldsymbol \\mu_i = b_{evo(i)} + b_{env(i)} + b_{i} + 3 + 1.1 \\boldsymbol t + 2.1 X_{i1} - 1.7 X_{i2} \n$$\n\n$$\n\\rho = 0.2,\\ X_{i1} \\sim Bin(1, 0.5),\\ X_{i2} \\sim Bin(1, 0.5),\\ \\boldsymbol t \\sim U_4(0,1)  \n$$\n\n$$\n\\boldsymbol \\Lambda_i  = \\left(\\begin{array}{cccc}\n1 & \\rho^{|t_{i1}-t_{i2}|} & \\rho^{|t_{i1}-t_{i3}|} & \\rho^{|t_{i1}-t_{i4}|}\\\\\n\\rho^{|t_{i2}-t_{i1}|} & 1 & \\rho^{|t_{i2}-t_{i3}|} & \\rho^{|t_{i2}-t_{i4}|}\\\\\n\\rho^{|t_{i3}-t_{i1}|} & \\rho^{|t_{i3}-t_{i2}|} & 1 & \\rho^{|t_{i3}-t_{i4}|}\\\\\n\\rho^{|t_{i4}-t_{i1}|} & \\rho^{|t_{i4}-t_{i2}|} & \\rho^{|t_{i4}-t_{i3}|} & 1\\\\\n\\end{array}\n\\right)\n$$\n\n## R\n\n::: incremental\n-   R is commonly used statistical programming language\n\n-   It has capabilities of simulating several probability models\n\n-   Certain R packages extends its capabilities to implement Bayesian models and MCMC techniques\n\n-   The brms, rstan, and cmdstanr are packages that allow to implement Bayesian models in Stan\n:::\n\n## Stan\n\n::: incremental\n-   Stan is newest MCMC program\n\n-   It utilizes the Hamiltonian Monte Carlo approach\n\n-   It uses BUGS programming\n\n-   The model is compiled and becomes executable in R or python\n:::\n\n## Stan Code\n\n\n\n::: {.cell}\n\n```{.default .cell-code}\ndata {\n  int N;\n  int D;\n  int S;\n  int H;\n  vector[N] X1;\n  vector[N] X2;\n  matrix[S,S] evo; \n  array[N] int<lower=1, upper=N> evo_id;\n  array[N] int<lower=1, upper=N> env_id;\n  array[N] vector[D] time;\n  array[N] matrix[D, D] time_diff;\n  array[N] vector[D] Y;\n}\n\ntransformed data {\n  vector[S] zero;\n  vector[D] ones;\n  zero = rep_vector(0, S);\n  ones = rep_vector(1, D);\n}\n\n\n\nparameters {\n  real<lower=0> sig_b;\n  real<lower=0> sig_h;\n  real<lower=0> sig_e;\n  real<lower=-1, upper=1> rho;\n  real b0;\n  real b1;\n  real b2;\n  real b3;\n  vector[S] evo_re;\n  vector[N] bb_re;\n  vector[H] hh_re;\n}\n\n\ntransformed parameters {\n  array[N] matrix[D,D] cov_1;\n  array[N] matrix[D,D] cov;\n  array[N] vector[D] yhat;\n  \n  for (n in 1:N){\n     yhat[n] = b0 * ones + \n                  b1 * time[n] + \n                  b2 * X1[n] * ones + \n                  b3 * X2[n] * ones + \n                  bb_re[n] * ones + \n                  evo_re[evo_id[n]] * ones +\n                  hh_re[env_id[n]] * ones;\n     cov_1[n] = pow(rho, time_diff[n]);\n     cov[n] = sig_e * cov_1[n];\n  } \n}\n\nmodel {\n  for (n in 1:N) {\n    Y[n] ~ multi_normal(yhat[n], cov[n]);\n  }\n  bb_re ~ normal(0, sig_b);\n  hh_re ~ normal(0, sig_h);\n  b0 ~ normal(0, 5);\n  b1 ~ normal(0, 5);\n  b2 ~ normal(0, 5);\n  evo_re ~ multi_normal(zero, evo);\n  sig_b ~ gamma(3, 2);\n  sig_e ~ gamma(1, 1);\n  sig_h ~ gamma(3, 2);\n  rho ~ uniform(-1, 1);\n}\n\n```\n:::\n\n\n\n## R Code\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Loading R Packages\nlibrary(mvtnorm)\nlibrary(tidyverse)\nlibrary(lme4)\nlibrary(cmdstanr)\nlibrary(bayesplot)\n\n## Compiling Stan Model to make executable\nmodel <- cmdstan_model(stan_file='~/Dropbox/Machine/new.stan')\n\n# Creating function\nkubrick <- function(k=NULL){\n  \n# Creating covariance matrix\nx1 <- c(1.00, 0.80, 0.10)\nx2 <- c(0.80, 1.30, 0.43)\nx3 <- c(0.10, 0.43, 1.90)\ncov_x <- as.matrix(rbind(x1, x2, x3))\n# Simulating species RE\nspecies_re <- rmvnorm(1, sigma = cov_x)\n# Simulating env RE\nenv_re <- rnorm(5, sd = sqrt(1.5))\n\n# Setting Parameters\nsig <- 1.5\nrho <- 0.2\nb0 <- 3\nb1 <- 1.1\nb2 <- 2.1\nb3 <- -1.7\n\n# Constructing Fake Data Set\niv <- 1\ndf <- data.frame()\nfor (i in 1:3){\n  for (ii in 1:5){\n    for (iii in 1:20){\n      bb <- rnorm(1, sd = sqrt(0.8))\n      time_shift <- rmvnorm(1, rep(0, 3), diag(rep(0.00001,3)))\n      time <- seq(0, 1, length.out = 4) + c(0, time_shift)\n      sigs <- (rho**as.matrix(dist(time, diag = T, upper = T)))*sig\n      x1 <- rbinom(1, 1, 0.5)\n      x2 <- rbinom(1, 1, 0.5)\n      mu <- species_re[i] + env_re[ii] + b0 + b1 * time +  b2 * x1 + b3 * x2 + bb\n      y <- rmvnorm(1, mu, sigs)\n      df <- rbind.data.frame(df, \n                             data.frame(t(rbind(y=y, \n                                                x1=x1,\n                                                x2=x2,\n                                                time=time, \n                                                bb=bb, \n                                                mu = mu,\n                                                time_id = 1:4,\n                                                i = i,\n                                                ii = ii,\n                                                iii = iii,\n                                                id = iv))))\n      iv <- iv + 1\n    }\n  }\n}\n\n#df |> head()\n#df |> dim()\n#df |> select(id) |> table()\n# Data Editing and extracting variables for stan\ntimes <- df |> \n  pivot_wider(id_cols = id, names_from = time_id, values_from = time)  |> \n  select(-id) |> \n  as.matrix()\n\nY <- df |> \n  pivot_wider(id_cols = id, names_from = time_id, values_from = V1)  |> \n  select(-id) |> \n  as.matrix()\n\ntime_diff <- array(dim = c(300, 4, 4))\nfor (i in 1:300){\n  time_diff[i,,] <- times[i,] |> dist(diag = T, upper = T) |> as.matrix()\n}\n\nevo_id <- df |> pivot_wider(id_cols = id, names_from = time_id, values_from = i) |> \n  select(`1`) |> as.vector() |> unlist() |> as.numeric()\nenv_id <- df |> pivot_wider(id_cols = id, names_from = time_id, values_from = ii) |> \n  select(`1`) |> as.vector() |> unlist() |> as.numeric()\n\n\nX1 <- df |> pivot_wider(id_cols = id, names_from = time_id, values_from = x1) |> \n  select(`1`) |> as.vector() |> unlist() |> as.numeric()\n\nX2 <- df |> pivot_wider(id_cols = id, names_from = time_id, values_from = x2) |> \n  select(`1`) |> as.vector() |> unlist() |> as.numeric()\n\n# Contruct Data list for stan\ndata <- list(\n  N = 300,\n  D = 4,\n  S = 3,\n  H = 5,\n  X1 = X1,\n  X2 = X2,\n  evo = cov_x,\n  evo_id = evo_id,\n  env_id = env_id,\n  time = times,\n  time_diff = time_diff,\n  Y = Y\n)\n\n\n# Fit Model with MCMC\nfit <- model$sample(data=data,\n                    iter_warmup = 10000,\n                    iter_sampling = 15000,\n                    thin = 5,\n                    adapt_delta = 0.9)\nresults <- fit$summary()\n# Return data set and MCMC\nreturn(list(data = data, fit = fit))\n\n}\n\n## Execute Function in Parallel\nkubrick()\n\n## Save the results\nsave(res, \"~/Dropbox/Machine/res/save.RData\")\n```\n:::\n\n\n\n## Frog Paper\n\n::: columns\n::: {.column width=\"50%\"}\n![](https://external-content.duckduckgo.com/iu/?u=https%3A%2F%2Fmedia1.giphy.com%2Fmedia%2FVGgzGCGmM3KYhMnKNY%2Fgiphy.gif&f=1&nofb=1&ipt=b7b2a9066f64385765a116bf63431bc3159ecb9dab59fc99d83611f57c173362&ipo=images)\n:::\n\n::: {.column width=\"50%\"}\n[Paper](https://academic.oup.com/icb/advance-article/doi/10.1093/icb/icae057/7688460)\n\n[Data](https://datadryad.org/stash/dataset/doi:10.5061/dryad.mw6m90650)\n:::\n:::\n\n## Thank You\n\n![](https://media.tenor.com/WjoUFaID8ScAAAAC/cat-cute.gif){fig-align=\"center\"}\n\n## Careers in Statistics\n\n::: columns\n::: {.column width=\"50%\"}\n### Careers\n\n-   Data Scientist\n\n-   Data Analyst\n\n-   Business Analyst\n\n-   Data Engineer\n\n-   Statistician\n\n-   Research Scientist\n:::\n\n::: {.column width=\"50%\"}\n### Industry\n\n-   Academia\n\n-   Pharmaceutical\n\n-   Government\n\n-   Tech\n\n-   Business/Finance\n\n-   Nonprofit\n\n-   Agriculture\n:::\n:::\n",
    "supporting": [
      "10_09_files"
    ],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {
      "include-after-body": [
        "\n<script>\n  // htmlwidgets need to know to resize themselves when slides are shown/hidden.\n  // Fire the \"slideenter\" event (handled by htmlwidgets.js) when the current\n  // slide changes (different for each slide format).\n  (function () {\n    // dispatch for htmlwidgets\n    function fireSlideEnter() {\n      const event = window.document.createEvent(\"Event\");\n      event.initEvent(\"slideenter\", true, true);\n      window.document.dispatchEvent(event);\n    }\n\n    function fireSlideChanged(previousSlide, currentSlide) {\n      fireSlideEnter();\n\n      // dispatch for shiny\n      if (window.jQuery) {\n        if (previousSlide) {\n          window.jQuery(previousSlide).trigger(\"hidden\");\n        }\n        if (currentSlide) {\n          window.jQuery(currentSlide).trigger(\"shown\");\n        }\n      }\n    }\n\n    // hookup for slidy\n    if (window.w3c_slidy) {\n      window.w3c_slidy.add_observer(function (slide_num) {\n        // slide_num starts at position 1\n        fireSlideChanged(null, w3c_slidy.slides[slide_num - 1]);\n      });\n    }\n\n  })();\n</script>\n\n"
      ]
    },
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}