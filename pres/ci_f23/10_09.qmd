---
title: "Bayesian Mixed Effects Models and Cats"
subtitle: "Analysis of Evolutionary Biological Data"
author: "Isaac Quintanilla Salinas"
format: 
  revealjs:
    touch: false
    controls: true
    pointer:
      pointerSize: 32
    incremental: false
    slide-number: true
    css: styles.css
knitr:
  opts_chunk: 
    echo: true
    eval: true
    message: false
    warnings: false
    comment: "#>" 
revealjs-plugins:
  - pointer
---

```{r}
#| include: false
library(tidyverse)
library(ggcats)
library(ThemePark)
```

# Motivation (Semi-Fake)

## San Bernardino Desert (Only Real Part)

![](https://upload.wikimedia.org/wikipedia/commons/0/05/Sand_to_Snow_National_Monument.jpg){fig-align="center"}

## Study *Felis*

::: columns
::: {.column width="30%"}
### *F. catus*

![](https://inaturalist-open-data.s3.amazonaws.com/photos/129658776/large.jpg){fig-align="left"}
:::

::: {.column width="30%"}
### *F. silvestris*

![](https://upload.wikimedia.org/wikipedia/commons/d/d0/Felis_silvestris_silvestris_Luc_Viatour.jpg){fig-align="center" width="455"}
:::

::: {.column width="30%"}
### *F. margarita*

![](https://upload.wikimedia.org/wikipedia/commons/thumb/a/af/Felis_margarita_10.jpg/220px-Felis_margarita_10.jpg){fig-align="right"}
:::
:::

## Study

**We are interested in seeing if wearing a flea collar will affect a cat's weight over time.**

## Outcome (Y): Weight of a cat

![](https://www.kentscientific.com/Customer-Content/www/products/Photos/Original/SCL-4000.jpg){fig-align="center"}

## Predictors (X)

-   Experimental Variable
    -   Flea Collar
-   Alertness
-   Hair Coat
-   Time

## Model

$$
Y = \boldsymbol X^\mathrm T\boldsymbol \beta + \varepsilon
$$

-   $Y$: Outcome of Interest

-   $\boldsymbol X = (1, t, X_1, X_2, X_3)^\mathrm T$: Predictor Variables

-   $\boldsymbol \beta=(\beta_0, \beta_1, \beta_2, \beta_3, \beta_4)^\mathrm T$: Regression Coefficients

-   $\varepsilon \sim N(0, \sigma^2)$

::: fragment
**Fit with Linear Regression**
:::

## Linear Regression Assumptions

::: incremental
-   Residuals follow a normal distribution

-   There is a linear trend

-   Constant Variance

-   Observations are Independent
:::

## Our Study

::: incremental
-   Residuals follow a normal distribution ✅

-   There is a linear trend ✅

-   Constant Variance ✅

-   Observations are Independent ❌
:::

## Why is this a problem?

::: columns
::: {.column width="50%"}
::: {.fragment .incremental}
-   Cannot Construct Likelihood Function

-   Biased Standard Errors

-   Uncontrollable Variation
:::
:::

::: {.column width="50%"}
```{r}
#| echo: false

df <- tibble(group = c("Measurement",
                       "Other"),
             y = c(33, 77))
ggplot(df, aes(fill=group, x = "", y = y)) + geom_bar(position = "stack", stat = "identity") + theme_void() +
  ggtitle("Error") +
  theme(legend.title = element_blank(),
        legend.position = "bottom",
        legend.text = element_text(size = 48),
        plot.title = element_text(size = 60, hjust = 0.5))
```
:::
:::

## Species

![](https://www.researchgate.net/publication/340201788/figure/fig1/AS:873450486902784@1585258232035/Maximum-Likelihood-phylogenetic-tree-constructed-using-whole-genome-SNPs-data-of-wildcat.jpg){fig-align="center"}

## Maine Coon

![](https://www.thesprucepets.com/thmb/MzKr6fC-v8W4D4oz2p9wWCwAFms=/2119x0/filters:no_upscale():strip_icc()/GettyImages-1189893683-e0ff70596b3b4f0687ba573e5a671f74.jpg){fig-align="center"}

## Environments

::: columns
::: {.column width="30%"}
::: {.fragment fragment-index="1"}
### Indoor

![](https://www.zooplus.ie/magazine/wp-content/uploads/2021/07/Indoor-Cat.jpeg){fig-align="left"}
:::
:::

::: {.column width="30%"}
::: {.fragment fragment-index="3"}
### In-Between

![](https://images.thdstatic.com/productImages/59613c83-0288-40bc-bf54-a15afca9d18f/svn/petsafe-cat-doors-hpa11-10876-31_600.jpg){fig-align="center"}
:::
:::

::: {.column width="30%"}
::: {.fragment fragment-index="2"}
### Outside

![](https://habitathaven.com/cdn/shop/articles/cat-outside-good-for-them_f08770c8-4ed6-4b54-ac5c-7880bd1b0b35_1000x.jpg?v=1669070035){fig-align="right"}
:::
:::
:::

## Longitudinal Measurements

```{r}
#| echo: false
set.seed(4)
df <- data.frame(x = 1:4,
                 y = 4 + rnorm(4, sd = 2),
                 image = rep("lil_bub", 4))

                           
ggplot(df) + geom_line(aes(x, y)) +
 geom_cat(aes(x, y, cat = image), size = 5) +
  ylim(c(1,7.5)) + 
  xlim(c(0.75, 4.25)) +
  xlab("Time") + ylab("Weight") +
  theme_barbie(axis.title.x = element_text(size = 48),
               axis.title.y = element_text(size = 48),
               axis.text.x = element_text(size = 42),
               axis.text.y = element_text(size = 42))
  
```

# Models

## Original Model

$$
Y_{k} = \boldsymbol X_{k}^\mathrm T\boldsymbol \beta + \varepsilon_{k}
$$

-   $k = 1, \ldots, N$

-   $N$: Number of all observations

-   $Y_{k}$: Outcome of Interest

-   $\boldsymbol X_{k} = (1, t_{k}, X_{k1}, X_{k2}, X_{k3})^\mathrm T$: Predictor Variables

-   $\boldsymbol \beta=(\beta_0, \beta_1, \beta_2, \beta_3, \beta_4)^\mathrm T$: Regression Coefficients

-   $\varepsilon_{k}\sim N(0, \sigma^2)$: Error Term

## Multilevel Model Approach

## Framework

```{r}
#| echo: false
df1 <- data.frame(x = runif(5, 2.25, 2.75),
                 y = runif(5, 22, 28),
                 image = sample(c("lil_bub", "maru", "pop_close", "venus", "toast"), 5))

df2 <- data.frame(x = runif(5, 3.25, 3.75),
                 y = runif(5, 32, 38),
                 image = sample(c("lil_bub", "maru", "pop_close", "venus", "toast"), 5))

df3 <- data.frame(x = runif(5, 4.25, 4.75),
                 y = runif(5, 42, 48),
                 image = sample(c("lil_bub", "maru", "pop_close", "venus", "toast"), 5))

df4 <- data.frame(x = runif(5, 2.25, 2.75),
                 y = runif(5, 32, 38),
                 image = sample(c("lil_bub", "maru", "pop_close", "venus", "toast"), 5))

df5 <- data.frame(x = runif(5, 2.25, 2.75),
                 y = runif(5, 42, 48),
                 image = sample(c("lil_bub", "maru", "pop_close", "venus", "toast"), 5))
df6 <- data.frame(x = runif(5, 3.25, 3.75),
                 y = runif(5, 22, 28),
                 image = sample(c("lil_bub", "maru", "pop_close", "venus", "toast"), 5))
df7 <- data.frame(x = runif(5, 3.25, 3.75),
                 y = runif(5, 42, 48),
                 image = sample(c("lil_bub", "maru", "pop_close", "venus", "toast"), 5))
df8 <- data.frame(x = runif(5, 4.25, 4.75),
                 y = runif(5, 32, 38),
                 image = sample(c("lil_bub", "maru", "pop_close", "venus", "toast"), 5))
df9 <- data.frame(x = runif(5, 4.25, 4.75),
                 y = runif(5, 22, 28),
                 image = sample(c("lil_bub", "maru", "pop_close", "venus", "toast"), 5))


a1 <- data.frame(
   x = c(2.5,3.5,4.5),
   y = c(52, 52, 52),
   label = c("F. catus", "F. sylvestris", "F. margarita")
)

a2 <- data.frame(
   x = c(1.9),
   y = c(25, 35, 45),
   label = c("Indoor", "In-Between", "Outdoor")
)


# basic graph
p <- ggplot() + theme_void()

# Add rectangles
p + annotate("rect", 
             xmin=c(2,3,4), xmax=c(3,4,5), 
             ymin=c(20,20,20), ymax=c(30,30,30), 
             alpha=0.2, color="red", fill="red") + 
  annotate("rect", 
           xmin=c(2,3,4), xmax=c(3,4,5), 
           ymin=c(30,30,30), ymax=c(40,40,40), 
           alpha=0.2, color="blue", fill="blue") +
  annotate("rect", 
           xmin=c(2,3,4), xmax=c(3,4,5), 
           ymin=c(40,40,40), ymax=c(50,50,50), 
           alpha=0.2, color="orange", fill="orange") +
  geom_cat(aes(x, y, cat = image), df1, size = 2) +
  geom_cat(aes(x, y, cat = image), df2, size = 2) +
  geom_cat(aes(x, y, cat = image), df3, size = 2) +
  geom_cat(aes(x, y, cat = image), df4, size = 2) +
  geom_cat(aes(x, y, cat = image), df5, size = 2) +
  geom_cat(aes(x, y, cat = image), df6, size = 2) +
  geom_cat(aes(x, y, cat = image), df7, size = 2) +
  geom_cat(aes(x, y, cat = image), df8, size = 2) +
  geom_cat(aes(x, y, cat = image), df9, size = 2) +
  geom_text(data=a1, aes( x=x, y=y, label=label),
           size=14 , fontface="bold.italic" ) +
  geom_text(data=a2, aes( x=x, y=y, label=label),
           size=12, angle = 90, fontface="bold" )
  

```

## Multilevel Model

## A Linear Model w/ Repeated Measurements

$$
Y_{ij} = \boldsymbol X_{ij}^\mathrm T\boldsymbol \beta + \varepsilon_{ij}
$$

-   $Y_{ij}=Y_i(t_{ij})$: Outcome of Interest

-   $\boldsymbol X_{ij} = (1, t_{ij}, X_{ij1}, X_{ij2}, X_{ij3})^\mathrm T$: Predictor Variables

-   $\boldsymbol \beta=(\beta_0, \beta_1, \beta_2, \beta_3, \beta_4)^\mathrm T$: Regression Coefficients

-   $\varepsilon_{ij}\sim N(0, \sigma^2)$: Error Term

## Animal-Specific Random Effects

$$
\boldsymbol b_i = (b_{i0}, b_{i1})^\mathrm T \sim N_2(\boldsymbol 0, \boldsymbol \Sigma_b)
$$

::: columns
::: {.column width="50%"}
### Mean Vector

$$
\boldsymbol 0 = \left(\begin{array}{c}
0 \\
0
\end{array}
\right)
$$
:::

::: {.column width="50%"}
### Covariance Matrix

$$
\boldsymbol \Sigma_b = \left(\begin{array}{cc}
\sigma_{b0}^2 & \sigma_{b01} \\
\sigma_{b01} & \sigma_{b1}^2 
\end{array}
\right)
$$
:::
:::

## Add Animal-Specific Random Effects

$$
Y_{ij} = \boldsymbol X_{ij}^\mathrm T\boldsymbol \beta + b_{i0} + t_{ij} b_{i1} + \varepsilon_{ij}
$$

::: columns
::: {.column width="50%"}
-   $Y_{ij}=Y_i(t_{ij})$: Outcome of Interest

-   $\boldsymbol X_{ij} = (1, t_{ij}, X_{ij1}, X_{ij2}, X_{ij3})^\mathrm T$: Predictor Variables

-   $\boldsymbol \beta=(\beta_0, \beta_1, \beta_2, \beta_3, \beta_4)^\mathrm T$: Regression Coefficients

-   $\varepsilon_{ij}\sim N(0, \sigma^2)$: Error Term
:::

::: {.column width="50%"}
-   $\boldsymbol b_i = (b_{i0}, b_{i1})^\mathrm T \sim N_2(\boldsymbol 0, \boldsymbol \Sigma_b)$
:::
:::

## Environmental-Specific Random Effects

$$
\boldsymbol b_i = (b_{i0}, b_{i1})^\mathrm T \sim N_2(\boldsymbol 0, \boldsymbol \Sigma_b)
$$

::: columns
::: {.column width="50%"}
### Mean Vector

$$
\boldsymbol 0 = \left(\begin{array}{c}
0 \\
0
\end{array}
\right)
$$
:::

::: {.column width="50%"}
### Covariance Matrix

$$
\boldsymbol \Sigma_b = \left(\begin{array}{cc}
\sigma_{b0}^2 & \sigma_{b01} \\
\sigma_{b01} & \sigma_{b1}^2 
\end{array}
\right)
$$
:::
:::

## Add Environmental-Specific Random Effects

$$
Y_{ij} = \boldsymbol X_{ij}^\mathrm T\boldsymbol \beta + b_{i0} + t_{ij} b_{i1} + b_{env(i)} +  \varepsilon_{ij}
$$

::: columns
::: {.column width="50%"}
-   $Y_{ij}=Y_i(t_{ij})$

-   $\boldsymbol X_{ij} = (1, t_{ij}, X_{ij1}, X_{ij2}, X_{ij3})^\mathrm T$

-   $\boldsymbol \beta=(\beta_0, \beta_1, \beta_2, \beta_3, \beta_4)^\mathrm T$

-   $\varepsilon_{ij}\sim N(0, \sigma^2)$
:::

::: {.column width="50%"}
-   $\boldsymbol b_i = (b_{i0}, b_{i1})^\mathrm T \sim N_2(\boldsymbol 0, \boldsymbol \Sigma_b)$
-   $b_{env(i)} \in \boldsymbol b_{env}=(b_{in}, b_{bw}, b_{out})^\mathrm T$
-   $\boldsymbol b_{env} \sim N_3(\boldsymbol 0, \sigma^2_{env} \boldsymbol I_3)$
:::
:::

## Species Random Effects

$$
\boldsymbol b_i = (b_{i0}, b_{i1})^\mathrm T \sim N_2(\boldsymbol 0, \boldsymbol \Sigma_b)
$$

::: columns
::: {.column width="50%"}
### Mean Vector

$$
\boldsymbol 0 = \left(\begin{array}{c}
0 \\
0 \\
0
\end{array}
\right)
$$
:::

::: {.column width="50%"}
### Covariance Matrix

$$
\boldsymbol \Sigma_b = \left(\begin{array}{cc}
\sigma_{c}^2 & \sigma_{cs} & \sigma_{cm}\\
\sigma_{sc} & \sigma_{s}^2 & \sigma_{sm} \\
\sigma_{mc} & \sigma_{ms} & \sigma_{m}^2 \\
\end{array}
\right)
$$
:::
:::

## Add Species Random Effects

$$
Y_{ij} = \boldsymbol X_{ij}^\mathrm T\boldsymbol \beta + b_{i0} + t_{ij} b_{i1} + b_{env(i)} + b_{evo(i)} + \varepsilon_{ij}
$$

::: columns
::: {.column width="50%"}
-   $Y_{ij}=Y_i(t_{ij})$

-   $\boldsymbol X_{ij} = (1, t_{ij}, X_{ij1}, X_{ij2}, X_{ij3})^\mathrm T$

-   $\boldsymbol \beta=(\beta_0, \beta_1, \beta_2, \beta_3, \beta_4)^\mathrm T$

-   $\varepsilon_{ij}\sim N(0, \sigma^2)$
:::

::: {.column width="50%"}
-   $\boldsymbol b_i = (b_{i0}, b_{i1})^\mathrm T \sim N_2(\boldsymbol 0, \boldsymbol \Sigma_b)$
-   $b_{env(i)} \in \boldsymbol b_{env}=(b_{in}, b_{bw}, b_{out})^\mathrm T$
-   $\boldsymbol b_{env} \sim N_3(\boldsymbol 0, \sigma^2_{env} \boldsymbol I_3)$
-   $b_{evo(i)} \in \boldsymbol b_{env}=(b_{cat}, b_{sil}, b_{mar})^\mathrm T$
-   $\boldsymbol b_{evo} \sim N_3(\boldsymbol 0, \boldsymbol \Sigma_{evo})$
:::
:::

## Final Model?

## Me ...

![](https://www.rd.com/wp-content/uploads/2022/04/GettyImages-1310147575.jpg?fit=700%2C466){fig-align="center"}

## Me ...

::: columns
::: {.column width="50%"}
::: incremental
-   We Must Use Random Effects

-   We Must Use a Bayesian Approach
:::
:::

::: {.column width="50%"}
![](https://www.rd.com/wp-content/uploads/2022/04/GettyImages-1310147575.jpg?fit=700%2C466){fig-align="center"}
:::
:::

## Add Correlation Matrix {.smaller}

$$
\widehat{\mathrm{cov}}( \boldsymbol Y_i) = \boldsymbol \Sigma_i = \sigma^2 \boldsymbol \Lambda_i
$$

::: fragment
$$
\boldsymbol \Lambda_i  = \left(\begin{array}{cccc}
1 & \rho^{(t_{i1}-t_{i2})^2} & \rho^{(t_{i1}-t_{i3})^2} & \rho^{(t_{i1}-t_{i4})^2}\\
\rho^{(t_{i2}-t_{i1})^2} & 1 & \rho^{(t_{i2}-t_{i3})^2} & \rho^{(t_{i2}-t_{i4})^2}\\
\rho^{(t_{i3}-t_{i1})^2} & \rho^{(t_{i3}-t_{i2})^2} & 1 & \rho^{(t_{i3}-t_{i4})^2}\\
\rho^{(t_{i4}-t_{i1})^2} & \rho^{(t_{i4}-t_{i2})^2} & \rho^{(t_{i4}-t_{i3})^2} & 1\\
\end{array}
\right)
$$
:::

::: fragment
$$
\boldsymbol \Lambda_i  = \left(\begin{array}{cccc}
1 & \rho^{|t_{i1}-t_{i2}|} & \rho^{|t_{i1}-t_{i3}|} & \rho^{|t_{i1}-t_{i4}|}\\
\rho^{|t_{i2}-t_{i1}|} & 1 & \rho^{|t_{i2}-t_{i3}|} & \rho^{|t_{i2}-t_{i4}|}\\
\rho^{|t_{i3}-t_{i1}|} & \rho^{|t_{i3}-t_{i2}|} & 1 & \rho^{|t_{i3}-t_{i4}|}\\
\rho^{|t_{i4}-t_{i1}|} & \rho^{|t_{i4}-t_{i2}|} & \rho^{|t_{i4}-t_{i3}|} & 1\\
\end{array}
\right)
$$
:::

::: fragment
$$
\rho \in (-1, 1)
$$
:::

## Final Model (for real, for now)

$$
\boldsymbol Y_i \sim N_4(\boldsymbol \mu_i, \boldsymbol \Sigma)
$$

## Accounted Variation

```{r}
#| echo: false

df <- tibble(group = c("Measurement",
                       "Biological",
                       "Environmental",
                       "Evolutionary",
                       "Time",
                       "Other"),
             y = c(35, 20, 26, 5, 12, 2))
ggplot(df, aes(fill=group, x = "", y = y)) + geom_bar(position = "stack", stat = "identity") + theme_void() +
  theme(legend.title = element_blank(),
        legend.position = "bottom",
        legend.text = element_text(size = 48))
```

# Bayesian Models

## Likelihood Function

## Prior

## Estimation

# 

::: columns
::: {.column width="50%"}
::: {style="font-size: 60px; padding: 120px 0;"}
**Markov Chain Monte Carlo Methods**
:::
:::

::: {.column width="50%"}
![](https://media.tenor.com/x5dpKrM1U6oAAAAd/vamonos-lets-go.gif)
:::
:::

## MCMC Methods

## Markov Chain

::: columns
::: {.column width="50%"}
:::

::: {.column width="50%"}
:::
:::

## Markov Kernel

::: columns
::: {.column width="50%"}
::: incremental
-   A Markov kernel provides the probability of going to another state, given the current state

-   Also known a transition matrix
:::
:::

::: {.column width="50%"}
::: fragement
```{r}
#| echo: false

df1 <- data.frame(x = c(0,2,4),
                 y = c(1,3,1),
                 image = c("lil_bub", 
                           "maru", 
                           "grumpy"))

ggplot() + theme_void() +
  geom_cat(aes(x, y, cat = image), df1, size = 8) +
  ylim(c(0,4.5)) +
  xlim(c(-1,5)) +
  geom_curve(aes(x = -.25, y = 1.6, xend = 1, yend = 2.9),
             arrow = arrow(length = unit(0.03, "npc"), type="closed"), 
             colour = "#EC7014", size = 3, curvature = -0.5, angle = 90) +
  geom_curve(aes(x = 4.5, y = 1.5, xend = 3.1, yend = 3.2),
             arrow = arrow(length = unit(0.03, "npc"), type="closed"), 
             colour = "#EC7014", size = 3, curvature = 0.5, angle = 90) +
  geom_curve(aes(x = 2.8, y = 3.3, xend = 1.9, yend = 3.5),
             arrow = arrow(length = unit(0.03, "npc"), type="closed"), 
             colour = "#EC7014", size = 3, curvature = 2, angle = 70) +
  geom_curve(aes(x = 2.3, y = 2.3, xend = 3.2, yend = 1.3),
             arrow = arrow(length = unit(0.03, "npc"), type="closed"), 
             colour = "navy", size = 3, curvature = .5, angle = 90) +
  geom_curve(aes(x = 3.2, y = 1, xend = 0.8, yend = 1),
             arrow = arrow(length = unit(0.03, "npc"), type="closed"), 
             colour = "forestgreen", size = 3, curvature = .2, angle = 90) +
  geom_curve(aes(x = 0.8, y = 0.6, xend = 3.1, yend = 0.7),
             arrow = arrow(length = unit(0.03, "npc"), type="closed"), 
             colour = "navy", size = 3, curvature = .2, angle = 90) +
  geom_curve(aes(x = 1.3, y = 2.4, xend = 0.9, yend = 1.4),
             arrow = arrow(length = unit(0.03, "npc"), type="closed"), 
             colour = "forestgreen", size = 3, curvature = -.3, angle = 90)



```
:::
:::
:::

## Stationary (limiting) distribution

::: columns
::: {.column width="50%"}
### Conditions

::: incremental
-   *Irreducibility:* The kernel allows for free movement of all the state space

-   *Recurrent:* The chain will return to any nonnegligible set an infinite number of times

-   *Aperiodic:* The chain can return to any state immediately
:::
:::

::: {.column width="50%"}
### Resulting

::: incremental
-   $X^{(t)}\rightarrow X$

    -   Regardless of $X^{(0)}$

-   $X \sim f$

    -   $f$: is a distribution function

-   $\frac{1}{T}\sum_{t=1}^{T} h\{X^{(t)}\} \rightarrow E_f\{h(X)\}$

    -   $h$: any integrable function

    -   by Law of Large Numbers

    -   known as Ergodic Theorem
:::
:::
:::

## Markov Chains Monte Carlo

## Metropolis-Hastings Algorithm

## Gibbs Sampling

## Hamiltonian Monte Carlo

# Simulation Study

## R

## Stan
